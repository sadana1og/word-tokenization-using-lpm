{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lpm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_hXqKxgkb87",
        "colab_type": "text"
      },
      "source": [
        "# Longest Prefix Matching Tokenization\n",
        "\n",
        "Applied to Thai Language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRHhjFPJxBXn",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLRxREEGfQs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def load_csv(path):\n",
        "    with open(path, \"r\") as file:\n",
        "        reader = csv.reader(file)\n",
        "        return_list = []\n",
        "        for row in reader:\n",
        "            return_list.append(row[0])\n",
        "    return return_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hTm1orPllNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6b07615e-043e-445a-ed65-7bd7043b3cea"
      },
      "source": [
        "THAI_CORPUS = load_csv(\"thai-corpus-from-NECTEC.csv\")\n",
        "THAI_CORPUS[:10]"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ก.',\n",
              " 'ก.ค.',\n",
              " 'ก.ต.',\n",
              " 'ก.ป.ส.',\n",
              " 'ก.พ.',\n",
              " 'ก.พ.ด.',\n",
              " 'ก.ม.',\n",
              " 'ก.ย',\n",
              " 'ก.ย.',\n",
              " 'ก.ร.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti66Bsx6lAsq",
        "colab_type": "text"
      },
      "source": [
        "## 2. Create corpus index -> optimize time complexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deBGjMlY1kio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Peek the corpus, look at the first character, and record its index\n",
        "def create_corpus_index(corpus): \n",
        "    index_list = []\n",
        "    curr_char = corpus[0][0]\n",
        "    cnt = 0\n",
        "    for idx, word in enumerate(corpus):\n",
        "        if idx == 0: \n",
        "            j = 0\n",
        "            while word[0] == word[j]:\n",
        "                j = j+1\n",
        "            index_list.append([word[0], 0, j+1])\n",
        "        elif idx == len(corpus)-1:\n",
        "            index_list.append({\"alphabet\": curr_char,\n",
        "                               \"start\": idx-cnt-1,\n",
        "                               \"end\": idx+1})\n",
        "        else:\n",
        "            last_char = curr_char\n",
        "            curr_char = word[0]\n",
        "            if last_char != curr_char:\n",
        "                index_list.append({\"alphabet\": last_char,\n",
        "                                   \"start\": idx-cnt-1,\n",
        "                                   \"end\": idx})\n",
        "                cnt = 0\n",
        "            else:\n",
        "                cnt = cnt+1\n",
        "    return index_list[1:]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA6iR2_XluQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6ed0d8e0-2c2f-4d53-e5a7-b7a8a406638f"
      },
      "source": [
        "CORPUS_INDEX = create_corpus_index(THAI_CORPUS)\n",
        "CORPUS_INDEX[:10]"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'alphabet': 'ก', 'end': 3425, 'start': 0},\n",
              " {'alphabet': 'ข', 'end': 4504, 'start': 3425},\n",
              " {'alphabet': 'ฃ', 'end': 4505, 'start': 4504},\n",
              " {'alphabet': 'ค', 'end': 7059, 'start': 4505},\n",
              " {'alphabet': 'ฅ', 'end': 7060, 'start': 7059},\n",
              " {'alphabet': 'ฆ', 'end': 7072, 'start': 7060},\n",
              " {'alphabet': 'ง', 'end': 7274, 'start': 7072},\n",
              " {'alphabet': 'จ', 'end': 8080, 'start': 7274},\n",
              " {'alphabet': 'ฉ', 'end': 8230, 'start': 8080},\n",
              " {'alphabet': 'ช', 'end': 9112, 'start': 8230}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NRiV0NKlMhl",
        "colab_type": "text"
      },
      "source": [
        "## 3. Word checking function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ul8y2RN4ioL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isWord(input_string, corpus, corpus_index):\n",
        "    if input_string == None: # input_string is none\n",
        "        return False\n",
        "    for index_obj in corpus_index:\n",
        "        try: # Check only first character with the corpus index\n",
        "            if index_obj[\"alphabet\"] == input_string[0]:\n",
        "                # Narrow the scope of checking\n",
        "                corpus_temp = corpus = corpus[index_obj[\"start\"]:index_obj[\"end\"]]\n",
        "                if(input_string in corpus_temp): \n",
        "                    return True\n",
        "                else:\n",
        "                    return False\n",
        "        except:\n",
        "            # The first character will never provide to become a word\n",
        "            # For instance, Thai consonants or some vowels\n",
        "            return False\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqn2ogbgl5bV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e5479285-0970-4df1-b70d-0a92f34783a4"
      },
      "source": [
        "print(isWord(\"ตากลม\", THAI_CORPUS, CORPUS_INDEX))\n",
        "print(isWord(\"ตากม\", THAI_CORPUS, CORPUS_INDEX))\n",
        "print(isWord(\"ตกลม\", THAI_CORPUS, CORPUS_INDEX))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRcSFnw8lSSk",
        "colab_type": "text"
      },
      "source": [
        "## 4. Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPPwXtcSjcaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lpm_tokenize(input_text, corpus, corpus_index):\n",
        "    st = 0 # word start pointer\n",
        "    end = len(input_text) + 1 # word end pointer\n",
        "    post_st = -1 # last word start pointer\n",
        "    post_end = -1 # last word end pointer\n",
        "    go_back = False # backward flag\n",
        "    found_misspell = False # undefined word flag\n",
        "    word_list = [] # word list\n",
        "    check_point = None # word list before append a current word\n",
        "    word = input_text[st:end] # initial word\n",
        "\n",
        "    while(len(input_text[st:end]) != 0):\n",
        "        while((isWord(input_string=word, corpus=corpus, corpus_index=corpus_index) == False) and (found_misspell == False)):\n",
        "            end = end-1 # end pointer be decreased til a word is found\n",
        "            if(end < st): # no word is found -> unfit occur\n",
        "                go_back = True\n",
        "                break\n",
        "            word = input_text[st:end] # repeat checking\n",
        "\n",
        "        if (go_back == False): # normal case: found a word -> set new pointers \n",
        "            post_st = st\n",
        "            post_end = end\n",
        "            st = end\n",
        "            end = len(input_text)+1\n",
        "            word_list.append(word) # append that word into a returnned list\n",
        "            check_point = word_list.copy() # save check point list\n",
        "\n",
        "        elif (go_back == True): # select the second longest\n",
        "            if (len(word_list) == 0): # condition: go back til no word left\n",
        "                if check_point == None: break # input text is not a word\n",
        "                word_list = check_point.copy() # load the check point\n",
        "                found_misspell = True # set a misspell flag\n",
        "                print(\"WARNING: WORD IS NOT IN CORPUS, TOKENIZING STOPPED.\")\n",
        "                break\n",
        "            word_list.pop() # unfit occur -> pop last word\n",
        "            st = post_st # set pointer back\n",
        "            end = post_end-1\n",
        "            go_back = False # then go check is it word again\n",
        "        word = input_text[st:end]\n",
        "    return word_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLRLG-Obmt6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3bc2e39b-3fc9-4d4f-9def-d7d4f1862e92"
      },
      "source": [
        "print(lpm_tokenize(\"ตากลมนั่งตากลม\", THAI_CORPUS, CORPUS_INDEX))\n",
        "print(lpm_tokenize(\"ตตากลม\", THAI_CORPUS, CORPUS_INDEX))\n",
        "print(lpm_tokenize(\"ตม\", THAI_CORPUS, CORPUS_INDEX))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ตากลม', 'นั่ง', 'ตากลม']\n",
            "[]\n",
            "['ตม']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s0s68znlZGU",
        "colab_type": "text"
      },
      "source": [
        "## 5. Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKiPtajFUky7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_text = \"เมื่อสุนัขตกจากสะพานชำรุดสู่ลำน้ำมันรีบว่ายขึ้นฝั่งเชิดหน้าสะบัดขนไม่บ่นว่าหรือด่าทอสะพานและก็ไม่ร้องขานแก้ตัวไม่มีสัตว์โลกชนิดใดเลยที่จะแก้ตัวให้กับความผิดพลาดของมันมันจะทำในสิ่งที่เหมาะสมกว่านั่นคือเริ่มต้นใหม่อย่างไม่ประมาทเมื่อบริสุทธิ์อย่างแท้จริงทำไมต้องพะวงกับการกล่าวหายามผิดพลาดอย่าพะวง\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxVoyKK8eOj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1a43d0ae-eb40-43bb-f421-e45b924ec2dc"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "print(lpm_tokenize(testing_text, THAI_CORPUS, INDEX_CORPUS))\n",
        "end = time.time()\n",
        "time = end - start\n",
        "print(str(time) + \" second\")"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['เมื่อ', 'สุนัข', 'ตก', 'จาก', 'สะพาน', 'ชำรุด', 'สู่', 'ลำน้ำ', 'มัน', 'รีบ', 'ว่าย', 'ขึ้นฝั่ง', 'เชิดหน้า', 'สะบัด', 'ขน', 'ไม่', 'บ่นว่า', 'หรือ', 'ด่าทอ', 'สะพาน', 'และ', 'ก็', 'ไม่', 'ร้อง', 'ขาน', 'แก้ตัว', 'ไม่มี', 'สัตว์โลก', 'ชนิด', 'ใด', 'เลย', 'ที่จะ', 'แก้ตัว', 'ให้', 'กับ', 'ความผิดพลาด', 'ของ', 'มัน', 'มัน', 'จะ', 'ทำ', 'ใน', 'สิ่ง', 'ที่', 'เหมาะสม', 'กว่า', 'นั่น', 'คือ', 'เริ่มต้น', 'ใหม่', 'อย่าง', 'ไม่', 'ประมาท', 'เมื่อ', 'บริสุทธิ์', 'อย่างแท้จริง', 'ทำไม', 'ต้อง', 'พะวง', 'กับ', 'การกล่าวหา', 'ยาม', 'ผิดพลาด', 'อย่า', 'พะวง']\n",
            "0.32450079917907715 second\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6OcukWjURD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}